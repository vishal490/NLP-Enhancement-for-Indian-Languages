{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b9b131-4841-4e3c-81e9-4bb4cff6b815",
   "metadata": {},
   "source": [
    "## If you are not using google colab then skip this cell"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4b990a4-98e2-402f-8b55-f1993e180a84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEqCA3KEDex2",
    "outputId": "c87baf9a-c8fb-461e-824e-47689c39f1ee"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf201524-4667-4c29-a909-b5fb19c34afb",
   "metadata": {},
   "source": [
    "## Install all Required modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46084732-1a57-479a-81e0-662f82306548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece \n",
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install protobuf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02b6fa-50db-4fd5-8114-7cc8b9797775",
   "metadata": {
    "id": "eb02b6fa-50db-4fd5-8114-7cc8b9797775"
   },
   "source": [
    "# Answer 1: Unicode correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad9f96fe-03b2-4285-b0eb-2d4582bf3acd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad9f96fe-03b2-4285-b0eb-2d4582bf3acd",
    "outputId": "47be00ab-4814-4e24-fca7-dbe0af844423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ऐ', 'स्', 'ई', 'स्', 'थ्', 'इ', 'त्', 'इ', 'म्', 'ए', 'अं', 'ए', 'क्', 'अ', 'न्', 'य्', 'आ', 'य्', 'अ', 'प्', 'ऊ', 'र्', 'ण्', 'अ', 'स्', 'अ', 'र्', 'अ', 'क्', 'आ', 'र्', 'अ', 'स्', 'आ', 'र्', 'व्', 'अ', 'ज्', 'अ', 'न्', 'इ', 'क्', 'अ', 'व्', 'इ', 'त्', 'त्', 'अ', 'क्', 'आ', 'इ', 'स्', 'अ', 'त्', 'अ', 'र्', 'अ', 'ह् ', 'अ', 'इ', 'स्', 'त्', 'ए', 'म्', 'आ', 'ल्', 'अ', 'क्', 'अ', 'र्', 'अ', 'त्', 'ई', 'ह् ', 'ऐ', 'क्', 'इ', 'स्', 'अं', 'स्', 'आ', 'ध्', 'अ', 'न्', 'ओ', 'अं', 'क्', 'आ', 'आ', 'व्', 'अं', 'ट्', 'अ', 'न्', 'अ']\n"
     ]
    }
   ],
   "source": [
    "# Mapping all consonant characters to their halant form\n",
    "hindi_consonants_with_halant = {\n",
    "    'क': 'क्', 'ख': 'ख्', 'ग': 'ग्', 'घ': 'घ्', 'ङ': 'ङ्',\n",
    "    'च': 'च्', 'छ': 'छ्', 'ज': 'ज्', 'झ': 'झ्', 'ञ': 'ञ्',\n",
    "    'ट': 'ट्', 'ठ': 'ठ्', 'ड': 'ड्', 'ढ': 'ढ्', 'ण': 'ण्',\n",
    "    'त': 'त्', 'थ': 'थ्', 'द': 'द्', 'ध': 'ध्', 'न': 'न्',\n",
    "    'प': 'प्', 'फ': 'फ्', 'ब': 'ब्', 'भ': 'भ्', 'म': 'म्',\n",
    "    'य': 'य्', 'र': 'र्', 'ल': 'ल्', 'ळ': 'ळ्', 'व': 'व्',\n",
    "    'श': 'श्', 'ष': 'ष्', 'स': 'स्', 'ह': 'ह् ','क़': 'क़्',\n",
    "    'ख़': 'ख़्', 'ग़': 'ग़्', 'ज़': 'ज़्', 'ड़': 'ड़्', 'ढ़': 'ढ़्',\n",
    "    'फ़': 'फ़्', 'य़': 'य़्', ' ':True\n",
    "}\n",
    "\n",
    "\n",
    "# Mapping maatras to their corresponding vowels\n",
    "map_to_vowel = {\n",
    "    'अ': 'अ', 'आ': 'आ', 'इ': 'इ', 'ई': 'ई', 'उ': 'उ',\n",
    "    'ऊ': 'ऊ', 'ऋ': 'ऋ', 'ॠ': 'ॠ', 'ऍ': 'ऍ', 'ऎ': 'ऎ',\n",
    "    'ए': 'ए', 'ऐ': 'ऐ', 'ऑ': 'ऑ', 'ऒ': 'ऒ', 'ओ': 'ओ',\n",
    "    'औ': 'औ','ा': 'आ', 'ि': 'इ', 'ी': 'ई', 'ु': 'उ', 'ू': 'ऊ',\n",
    "    'ृ': 'ऋ', 'ॄ': 'ॠ', 'ॅ': 'ऍ', 'ॆ': 'ऎ', 'े': 'ए',\n",
    "    'ै': 'ऐ', 'ॉ': 'ऑ', 'ॊ': 'ऒ', 'ो': 'ओ', 'ौ': 'औ','ं':'अं','ः':'अः','ँ':'अं','ृ':'र्'\n",
    "}\n",
    "\n",
    "# Defining speacial symbols\n",
    "special_symbols = ['।', '?', ',', ':', ';', '-', '—', '–', '\"', \"'\", '(', ')', '[', ']']\n",
    "\n",
    "\n",
    "# Function to for unicide correctoin\n",
    "def transform(sentence):\n",
    "    sentence_char = []\n",
    "    \n",
    "    for i in range(0,len(sentence)):\n",
    "        char = sentence[i]\n",
    "        next_char = False\n",
    "\n",
    "        # if char is space then move to next symbol\n",
    "        if char == ' ' :\n",
    "            continue\n",
    "\n",
    "        # next_char is variable to check if word is ending with full consonant(without matras) or not\n",
    "        if i<(len(sentence)-1):\n",
    "            if (sentence[i+1] in special_symbols and sentence[i+1] not in map_to_vowel) or sentence[i+1] in hindi_consonants_with_halant:\n",
    "                next_char = True\n",
    "\n",
    "\n",
    "        if char in hindi_consonants_with_halant:\n",
    "            if i+1 >= len(sentence):\n",
    "                next_char = True\n",
    "            sentence_char.append(hindi_consonants_with_halant.get(char))\n",
    "            if next_char:\n",
    "                sentence_char.append('अ')\n",
    "\n",
    "        elif char in map_to_vowel:\n",
    "            sentence_char.append(map_to_vowel.get(char))\n",
    "            \n",
    "    return sentence_char\n",
    "print(transform(\" ऐसी स्थिति में एक न्यायपूर्ण सरकार, सार्वजनिक वित्त का इस तरह इस्तेमाल करती है कि संसाधनों   का आवंटन \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c7566-0481-46a9-8644-8723476cab1f",
   "metadata": {
    "id": "b01c7566-0481-46a9-8644-8723476cab1f"
   },
   "source": [
    "# Answer 2:Finding characters and syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdb909-bb41-4b3e-b068-ceb3ea2cd893",
   "metadata": {},
   "source": [
    "## Function to read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "Sp6EqND_wuKi",
   "metadata": {
    "id": "Sp6EqND_wuKi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read data file and create a dataframe \n",
    "def read_file(path):\n",
    "    # Read the text file into a list of lines and remove '\\n' from each line\n",
    "    with open(path, \"r\",encoding = \"UTF8\") as file:\n",
    "        lines = [line.rstrip(\"\\n\") for line in file.readlines()]\n",
    "\n",
    "    # Create a DataFrame from the list of lines\n",
    "    df = pd.DataFrame(lines, columns=[\"Text\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "XMbMd_cUw54N",
   "metadata": {
    "id": "XMbMd_cUw54N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिया...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>मोदी सरकार के पहले कार्यकाल में भी तीन तलाक को...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पूनम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक व...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0       आवेदन करने की आखिरी तारीख 31 जनवरी, 2020 है।\n",
       "1  इतनी दुआ कर दो हमारे लिए कि जितना प्यार दुनिया...\n",
       "2  मोदी सरकार के पहले कार्यकाल में भी तीन तलाक को...\n",
       "3  भाजपा के दिवंगत नेता प्रमोद महाजन की बेटी पूनम...\n",
       "4  ऐसी स्थिति में एक न्यायपूर्ण सरकार सार्वजनिक व..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data corpus of hindi\n",
    "data = read_file(\"./data/hi_100.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365281c-b7b9-4555-8d1f-295b3eabd483",
   "metadata": {
    "id": "c365281c-b7b9-4555-8d1f-295b3eabd483"
   },
   "source": [
    "## Let's define some useful functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25747a7e-76e4-4f8a-a813-0a57a94bfc69",
   "metadata": {},
   "source": [
    "### (A)  Function to sort dictionary based on values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a723b631-05a7-4cea-b9cd-dac98561fff6",
   "metadata": {
    "id": "a723b631-05a7-4cea-b9cd-dac98561fff6"
   },
   "outputs": [],
   "source": [
    "def sort_all(name):\n",
    "    return dict(sorted(name.items(),key = lambda item:item[1],reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de4bf94-aab2-4bc3-9e3d-1e589a64f9b5",
   "metadata": {},
   "source": [
    "### (B) Function to generate csv files , (result parameter)  is a dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0360bc4-343d-4a60-90b7-afa4bf36cf96",
   "metadata": {
    "id": "b0360bc4-343d-4a60-90b7-afa4bf36cf96"
   },
   "outputs": [],
   "source": [
    "def generate_files(result,prefix=\"\"):\n",
    "    filenames = {}\n",
    "    for key, value in result.items():\n",
    "        df = pd.DataFrame(value.items(), columns=['item', 'frequency'])\n",
    "        filename = f\"{prefix}_{key}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        filenames[key] = filename\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd8cb9-c9e3-4f35-a3e5-c7f4454a7591",
   "metadata": {},
   "source": [
    "### (C) Function to process the words/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "I2R00RrYGsWi",
   "metadata": {
    "id": "I2R00RrYGsWi"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_tokens(tokens):\n",
    "  # Defining 4 empty dictionaries\n",
    "  uni_character_dict = {}\n",
    "  bi_character_dict = {}\n",
    "  uni_syllables_dict = {}\n",
    "  bi_syllables_dict = {}\n",
    "  # iterarting on each token/words of list of token/words\n",
    "  for word in tokens:\n",
    "            # processing each the token/word\n",
    "            character_list = transform(word)\n",
    "            # print(character_list)\n",
    "            uni_syll = \"\"\n",
    "            bi_syll  = \"\"\n",
    "            bi_char=\"\"\n",
    "            counter = 0\n",
    "            char_flag = 0\n",
    "            # iterating character list\n",
    "            for char in character_list:\n",
    "                \n",
    "                # Forming character count\n",
    "                char_flag += 1\n",
    "                bi_char += char\n",
    "                if char in uni_character_dict:\n",
    "                    uni_character_dict[char] += 1\n",
    "                else:\n",
    "                    uni_character_dict[char] = 1\n",
    "\n",
    "\n",
    "                if char_flag%2==0 :\n",
    "                    if bi_char in bi_character_dict:\n",
    "                        bi_character_dict[bi_char] += 1\n",
    "\n",
    "                    else:\n",
    "                        bi_character_dict[bi_char] = 1\n",
    "                    bi_char=\"\"\n",
    "                    char_flag = 0\n",
    "\n",
    "                # forming syllables count\n",
    "                uni_syll += char\n",
    "                bi_syll +=  char\n",
    "                if char in map_to_vowel:\n",
    "                    if uni_syll in uni_syllables_dict:\n",
    "                        uni_syllables_dict[uni_syll] += 1\n",
    "\n",
    "                    else:\n",
    "                        uni_syllables_dict[uni_syll] = 1\n",
    "                    counter += 1\n",
    "                    uni_syll=\"\"\n",
    "                    if counter == 2:\n",
    "                        if bi_syll in bi_syllables_dict:\n",
    "                            bi_syllables_dict[bi_syll] += 1\n",
    "\n",
    "                            bi_syll = \"\"\n",
    "                        else:\n",
    "                            bi_syllables_dict[bi_syll] = 1\n",
    "                        counter = 0\n",
    "                        bi_syll = \"\"\n",
    "  return {\n",
    "        \"uni_character\": uni_character_dict,\n",
    "        \"bi_character\": bi_character_dict,\n",
    "        \"uni_syllables\": uni_syllables_dict,\n",
    "        \"bi_syllables\": bi_syllables_dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5197852-6b91-4392-b81f-39d33552757a",
   "metadata": {},
   "source": [
    "### (D) Function to process the sentences from whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "CAncpT2CHiMf",
   "metadata": {
    "id": "CAncpT2CHiMf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_corpus(corpus):\n",
    "    result = {\n",
    "        \"uni_character\": {},\n",
    "        \"bi_character\": {},\n",
    "        \"uni_syllables\": {},\n",
    "        \"bi_syllables\": {}\n",
    "    }\n",
    "\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split(\" \")\n",
    "        words_result = process_tokens(words)\n",
    "        for key, value in words_result.items():\n",
    "            for k, v in value.items():\n",
    "                if k in result[key]:\n",
    "                    result[key][k] += v  # Add frequencies to existing keys\n",
    "                else:\n",
    "                    result[key][k] = v   # Initialize if key does not exist\n",
    "    for key in result:\n",
    "        result[key] = sort_all(result[key])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638840f-862a-4ee6-bed9-16deacdb050e",
   "metadata": {},
   "source": [
    "### Warning: Following cell will take 5 to 7 minutes to execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ennFLcO0JPKm",
   "metadata": {
    "id": "ennFLcO0JPKm"
   },
   "outputs": [],
   "source": [
    "# generating characters and syllables for whole data set\n",
    "result = process_corpus(data[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "t3dimPHyHt7j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3dimPHyHt7j",
    "outputId": "6a2f0097-da61-465f-e371-125728e5a0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files generated :\n",
      "uni_character\n",
      "bi_character\n",
      "uni_syllables\n",
      "bi_syllables\n"
     ]
    }
   ],
   "source": [
    "# Generating files\n",
    "generated_files = generate_files(result)\n",
    "print(\"Files generated :\")\n",
    "for keys,_ in generated_files.items():\n",
    "    print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cefdb871-02a2-4810-937d-44b46656c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 freqencies:\n",
      "top_20_items_uni_char: {'अ': 6911859, 'आ': 2991109, 'ए': 2318442, 'क्': 2219964, 'र्': 2140164, 'ई': 1460305, 'इ': 1432973, 'न्': 1334448, 'स्': 1283708, 'अं': 1215588, 'ह् ': 1133159, 'म्': 1053237, 'त्': 980066, 'ल्': 919917, 'ओ': 896588, 'प्': 805896, 'य्': 752819, 'व्': 624743, 'द्': 607633, 'उ': 587149}\n",
      "\n",
      "\n",
      "top_20_items_bi_character: {'र्अ': 784810, 'क्अ': 455914, 'क्ए': 363263, 'न्अ': 351174, 'स्अ': 331978, 'ह् ऐ': 296843, 'प्अ': 278831, 'म्ए': 277981, 'न्ए': 267298, 'ल्अ': 261429, 'क्आ': 261002, 'त्अ': 259598, 'ह् अ': 253367, 'म्अ': 243201, 'क्ई': 224699, 'ब्अ': 218062, 'य्आ': 212870, 'क्इ': 188062, 'क्ओ': 185728, 'स्ए': 184827}\n",
      "\n",
      "\n",
      "top_20_items_uni_syllables: {'र्अ': 998460, 'क्अ': 565081, 'न्अ': 490374, 'स्अ': 467169, 'क्ए': 403141, 'प्अ': 370202, 'ल्अ': 322731, 'न्ए': 308334, 'क्आ': 304067, 'ह् ऐ': 296989, 'म्ए': 293786, 'म्अ': 285874, 'त्अ': 285450, 'ह् अ': 262318, 'ए': 260373, 'अ': 250340, 'क्ई': 243146, 'ब्अ': 230677, 'य्आ': 223239, 'स्ए': 215169}\n",
      "\n",
      "\n",
      "top_20_items_bi_syllables: {'क्अर्अ': 133732, 'और्अ': 115082, 'प्अर्अ': 94334, 'इस्अ': 81620, 'एक्अ': 54039, 'ल्इए': 53765, 'न्अह् ई': 49306, 'अप्अ': 44009, 'क्इय्आ': 36892, 'क्अह् आ': 33052, 'क्आर्अ': 31511, 'य्अह् अ': 31232, 'ग्अय्आ': 30231, 'आप्अ': 28611, 'उन्अ': 27670, 'स्आथ्अ': 27510, 'स्अर्अ': 26935, 'उस्अ': 26188, 'ब्आद्अ': 24502, 'र्अह् ए': 24366}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top 20 freqencies:\")\n",
    "top_20_items_uni_char = dict(list(result['uni_character'].items())[:20])\n",
    "top_20_items_bi_character = dict(list(result['bi_character'].items())[:20])\n",
    "top_20_items_uni_syllables = dict(list(result['uni_syllables'].items())[:20])\n",
    "top_20_items_bi_syllables = dict(list(result['bi_syllables'].items())[:20])\n",
    "print(f\"top_20_items_uni_char: {top_20_items_uni_char}\")\n",
    "print(\"\\n\")\n",
    "print(f\"top_20_items_bi_character: {top_20_items_bi_character}\")\n",
    "print(\"\\n\")\n",
    "print(f\"top_20_items_uni_syllables: {top_20_items_uni_syllables}\")\n",
    "print(\"\\n\")\n",
    "print(f\"top_20_items_bi_syllables: {top_20_items_bi_syllables}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e212e6-3ae2-481b-934b-65ae2e722db0",
   "metadata": {},
   "source": [
    "# Answer 3: Solved on the mentioned website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b6d06-5a6b-4fc8-8f63-29fd158d58b1",
   "metadata": {
    "id": "c2fdd58e-b82d-4644-9a6b-cbddf354c6c4"
   },
   "source": [
    "# Answer 4 : Unigram, BPE , mBERT , IndicBER and White-space tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb5f6d25-5924-4a98-8183-0014c8c40e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f90fbe-adf6-447a-b59b-c19858b9a98f",
   "metadata": {},
   "source": [
    "## (4.1) mBERT and IndicBERT tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b896dc83-18a0-49d2-b7e4-083a31e3d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokization using mBERT and IndicBERT\n",
    "def tokenization_step(tokenizer, maxlen, model_name,data = data):\n",
    "    tokens = []\n",
    "    token_counts = Counter()  # Counter to keep track of token frequencies\n",
    "\n",
    "    if model_name == 'IndicBERT':\n",
    "        for sentence in data[\"Text\"]:\n",
    "            sentence_tokens = tokenizer.tokenize(sentence)\n",
    "            tokens += sentence_tokens\n",
    "            token_counts.update(sentence_tokens)\n",
    "    elif model_name == 'mBERT':\n",
    "        for sentence in data[\"Text\"]:\n",
    "            sentence_tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(sentence, truncation=True))\n",
    "            tokens += sentence_tokens\n",
    "            token_counts.update(sentence_tokens)\n",
    "\n",
    "    return tokens, token_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ff0f8-d48b-4bb1-8378-d238a3f9609f",
   "metadata": {},
   "source": [
    "## (4.2) Unigram and BPE tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1NF40xVruAUy",
   "metadata": {
    "id": "1NF40xVruAUy"
   },
   "outputs": [],
   "source": [
    "\n",
    "# tokenization using unigram and BPE\n",
    "def Unigram_and_BPE_tokenization(model_vocab,data =data):\n",
    "      all_tokens = []\n",
    "      # Load trained Hindi Unigram model\n",
    "      hindi_model = f\"{model_vocab}.model\"\n",
    "\n",
    "      hindi_tokenizer = spm.SentencePieceProcessor(model_file=hindi_model)\n",
    "\n",
    "\n",
    "      # Initialize Counter for token frequencies\n",
    "      token_counts = Counter()\n",
    "\n",
    "      # Tokenize each sentence in the corpus and update token frequencies\n",
    "      for sentence in data[\"Text\"]:\n",
    "          tokens = hindi_tokenizer.encode_as_pieces(sentence)\n",
    "          all_tokens += tokens\n",
    "          token_counts.update(tokens)\n",
    "      return all_tokens,token_counts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df0be0-4d04-4c3c-ac45-27b45fc4616f",
   "metadata": {},
   "source": [
    "## (4.3)  Whitespace tokenization tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "720e3e32-14e0-4a90-81bf-a8a230c7a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization using whitespace tokenizer\n",
    "def whitespace_tokenizer(data=data):\n",
    "    # List to store all tokens\n",
    "    all_tokens = []\n",
    "\n",
    "    # Iterate through each sentence in the group\n",
    "    for sentence in data[\"Text\"]:\n",
    "        # Tokenize the sentence based on white spaces\n",
    "        tokens = sentence.strip().split()\n",
    "        # Add the tokens to the list of all tokens\n",
    "        all_tokens.extend(tokens)\n",
    "\n",
    "    # Count the frequency of each token\n",
    "    token_freq = Counter(all_tokens)\n",
    "\n",
    "    return all_tokens,token_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470302c7-6ce2-4e34-9a7a-24edc853a603",
   "metadata": {},
   "source": [
    "### Loading IndicBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "IIXOeV9ln61q",
   "metadata": {
    "id": "IIXOeV9ln61q"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "euJ41yQ5oCtU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a8160c1596ce4d73bf2d46868f71aeae",
      "1e764f07298a4ca3ae0464c6826370d2",
      "9b828cb7454345589a99bb43c5ea2f8c",
      "f4a41a33dc5c4813b958bba004ca2566",
      "fa5d96e35a2b4f03ac73ad4de273d3a3",
      "69501c90e60e4066a4a599f69a237311",
      "063c8094343b4dfa906e2b4bb6812915",
      "c8fe8e3396f34edabf7597cca66088dd",
      "237dd2b7df8247e991bb448e61c98e16",
      "00691d80a0534d96a2b3a758f06c468a",
      "ea01a2a7836c43bd9119ad8bb052668a",
      "301c7cb8821d46f1ba857e4d7bb39be4",
      "f3939ae9f38640c9817300dd542ed94d",
      "a149c5f814194f328379a9506e3284a0",
      "e1a5a843c9114c8bbd59c84d9e8c698c",
      "28667b8b571342acab0aeeae3d5bbdb5",
      "fca72bd9d12244f383138f2f90113b63",
      "e09d6e0780704603906521cd9ccb8a2e",
      "9248c179265b45cdbbf08fd92eaa4a9b",
      "a07a0d0bc0d34ebe9d1a1730010d0185",
      "65e24d0503994f8893c8adde322969a0",
      "db420eea2d474427abce15b033fd5f85"
     ]
    },
    "id": "euJ41yQ5oCtU",
    "outputId": "050bf54d-25c7-4027-ec83-359ce141963d"
   },
   "outputs": [],
   "source": [
    "Indic_tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert', keep_accents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d71e5-5b6e-4861-b093-aed6e456b0a5",
   "metadata": {},
   "source": [
    "### Tokinizationation using IndicBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fbd83d-414d-42ef-9fc5-ac8df33c5f79",
   "metadata": {},
   "source": [
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bHkpez7Pr5M_",
   "metadata": {
    "id": "bHkpez7Pr5M_"
   },
   "outputs": [],
   "source": [
    "IndicBERT_token_1000,IndicBERT_token_1000_count =  tokenization_step(Indic_tokenizer,1000,'IndicBERT')\n",
    "IndicBERT_token_2000,IndicBERT_token_2000_count =  tokenization_step(Indic_tokenizer,2000,'IndicBERT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1756e-385c-4eee-9051-a8954e18ef61",
   "metadata": {},
   "source": [
    "### Loading mBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "focRJD_zsnPG",
   "metadata": {
    "id": "focRJD_zsnPG"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "mBERT_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09c775-d418-44b4-a3ec-58a4d9d8b805",
   "metadata": {},
   "source": [
    "### Tokenization using mBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d6379-96b7-4e52-9bd3-05bc2537c578",
   "metadata": {},
   "source": [
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7SZYWZBLx102",
   "metadata": {
    "id": "7SZYWZBLx102"
   },
   "outputs": [],
   "source": [
    "mBERT_token_1000,mBERT_token_1000_count = tokenization_step(mBERT_tokenizer,1000,'mBERT')\n",
    "mBERT_token_2000,mBERT_token_2000_count = tokenization_step(mBERT_tokenizer,2000,'mBERT')\n",
    "result_token_count = {\n",
    "    \"mBERT_token_mxln_1000_count\":dict(mBERT_token_1000_count),\n",
    "    \"mBERT_token_mxln_2000_count\":dict(mBERT_token_2000_count),\n",
    "    \"IndicBERT_maxln_token_1000_count\":dict(IndicBERT_token_1000_count),\n",
    "    \"IndicBERT_maxln_token_2000_count\":dict(IndicBERT_token_2000_count)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c9257-c649-4270-abc4-0c7234ae991f",
   "metadata": {},
   "source": [
    "### generating  characters and syllables from tokenizes list\n",
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "tjOKZaaJx_4A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjOKZaaJx_4A",
    "outputId": "3d185e06-19ff-44da-baa5-ab3519f9491b"
   },
   "outputs": [],
   "source": [
    "indiBERT_1000 = process_tokens(IndicBERT_token_1000)\n",
    "indiBERT_2000 = process_tokens(IndicBERT_token_2000)\n",
    "mBERT_1000 = process_tokens(mBERT_token_1000)\n",
    "mBERT_2000 = process_tokens(mBERT_token_2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "IRtnNuaHL-NP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRtnNuaHL-NP",
    "outputId": "2bfbeece-e04b-4966-b21f-faf1b5c30a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have Generated !\n"
     ]
    }
   ],
   "source": [
    "# File generation for IndicBERET and mBERT\n",
    "generate_files(indiBERT_1000,\"indiBERT_mxln_1000\")\n",
    "generate_files(indiBERT_2000,\"indiBERT_mxln_2000\")\n",
    "generate_files(mBERT_1000,\"mBERT_mxln_1000\")\n",
    "generate_files(mBERT_2000,\"mBERT_mxln_2000\")\n",
    "generate_files(result_token_count)\n",
    "print(\"All files have Generated !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91a473-6592-4efb-bbd8-1e31707a11cf",
   "metadata": {},
   "source": [
    "## Training Unigram model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb8f09-a6a0-4fca-9bd5-bab5ed94c0f5",
   "metadata": {},
   "source": [
    "### warning : it will approx 10 minutes to execute or you can skip training i have already saved the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7pyNu2PnUULq",
   "metadata": {
    "id": "7pyNu2PnUULq"
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Train Unigram model vocab size = 1000\n",
    "spm.SentencePieceTrainer.train('--input=./data/hi_100.txt --model_prefix=unigram_model_1000_vocab --vocab_size=1000 --model_type=unigram')\n",
    "\n",
    "# Train Unigram model vocab size = 2000\n",
    "spm.SentencePieceTrainer.train('--input=./data/hi_100.txt --model_prefix=unigram_model_2000_vocab --vocab_size=2000 --model_type=unigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afadad7-8f3c-4842-a8c9-208cabcc7f3c",
   "metadata": {},
   "source": [
    "## Training BPE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a74ab6-99a7-4cb1-8aac-eebe1a1f717c",
   "metadata": {},
   "source": [
    "### warning : it will approx 10 minutes to execute or you can skip training i have already saved the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "n_dwDwxl8ipk",
   "metadata": {
    "id": "n_dwDwxl8ipk"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train SentencePiece tokenizer with BPE\n",
    "spm.SentencePieceTrainer.train(input=\"./data/hi_100.txt\", model_prefix=\"BPE_model_1000_vocab\", vocab_size=1000, model_type='bpe')\n",
    "spm.SentencePieceTrainer.train(input=\"./data/hi_100.txt\", model_prefix=\"BPE_model_2000_vocab\", vocab_size=2000, model_type='bpe')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bff02-b0a4-4a8c-937e-3d195c818edf",
   "metadata": {},
   "source": [
    "### Tokenization using Unigram and BPE we will use already trained saved models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841a484-671a-4205-8bbc-63ba41b11d29",
   "metadata": {},
   "source": [
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3_CY8vE_zvZI",
   "metadata": {
    "id": "3_CY8vE_zvZI"
   },
   "outputs": [],
   "source": [
    "\n",
    "unigram_vocab_1000_token, unigram_vocab_1000_token_freq  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/unigram_model/unigram_model_1000_vocab\")\n",
    "unigram_vocab_2000_token, unigram_vocab_2000_token_freq  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/unigram_model/unigram_model_2000_vocab\")\n",
    "\n",
    "BPE_vocab_1000_token, BPE_vocab_1000_token_freq  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/BPE_model/BPE_model_1000_vocab\")\n",
    "BPE_vocab_2000_token, BPE_vocab_2000_token_freq  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/BPE_model/BPE_model_1000_vocab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fbb5d-8ac0-4e35-a2f1-a0e566e0687c",
   "metadata": {},
   "source": [
    "### generating characters and syllables from tokenized list\n",
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5GEqKlecEshE",
   "metadata": {
    "id": "5GEqKlecEshE"
   },
   "outputs": [],
   "source": [
    "unigram_vocab_1000 = process_tokens(unigram_vocab_1000_token)\n",
    "unigram_vocab_2000 = process_tokens(unigram_vocab_2000_token)\n",
    "BPE_vocab_1000 = process_tokens(BPE_vocab_1000_token)\n",
    "BPE_vocab_2000 = process_tokens(BPE_vocab_2000_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "tZRd-VNTC-cX",
   "metadata": {
    "id": "tZRd-VNTC-cX"
   },
   "outputs": [],
   "source": [
    "result_BPE_uni_token_count = {\n",
    "    \"unigram_vocab_1000_token_freq\":dict(unigram_vocab_1000_token_freq),\n",
    "    \"unigram_vocab_2000_token_freq\":dict(unigram_vocab_2000_token_freq),\n",
    "    \"BPE_vocab_1000_token_freq\":dict(BPE_vocab_1000_token_freq),\n",
    "    \"BPE_vocab_2000_token_freq\":dict(BPE_vocab_2000_token_freq)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab790811-3e37-4f53-859f-7f6345701e8c",
   "metadata": {},
   "source": [
    "### Tokenization using whitespace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "D20LQL5cELR3",
   "metadata": {
    "id": "D20LQL5cELR3"
   },
   "outputs": [],
   "source": [
    "whitespace_tokenizer_token,whitespace_tokenizer_count = whitespace_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013da878-5ea8-4dfc-a428-ab5a8bc2e8c3",
   "metadata": {},
   "source": [
    "### generating characters and syllables from tokenized list\n",
    "### warning : it will 5 to 10 minutes to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7rhf7kkEfnV",
   "metadata": {
    "id": "a7rhf7kkEfnV"
   },
   "outputs": [],
   "source": [
    "whitespace_token = process_tokens(whitespace_tokenizer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dIu7XOe0FzZ7",
   "metadata": {
    "id": "dIu7XOe0FzZ7"
   },
   "outputs": [],
   "source": [
    "result_whitespcase_token_count = {\n",
    "    \"whitespace_token\":dict(whitespace_tokenizer_count)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89dd6ce-935a-4526-9415-74053cf841ce",
   "metadata": {},
   "source": [
    "### File generation Unigram , BPE , Whitespace Tokenizer will some  time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9602a158-f6e8-4e82-831e-64254398acb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5or_fIsi7s8W",
    "outputId": "3b18b6f6-ebcf-4c93-a4d7-01c7958f512d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have generated succesfully!\n"
     ]
    }
   ],
   "source": [
    "# File generation Unigram , BPE , Whitespace Tokenizer\n",
    "generate_files(unigram_vocab_1000,\"unigram_vocab_1000\")\n",
    "generate_files(unigram_vocab_2000,\"unigram_vocab_2000\")\n",
    "generate_files(BPE_vocab_1000,\"BPE_vocab_1000\")\n",
    "generate_files(BPE_vocab_2000,\"BPE_vocab_2000\")\n",
    "generate_files(result_BPE_uni_token_count)\n",
    "\n",
    "generate_files(whitespace_token,\"whitespace_token\")\n",
    "generate_files(result_whitespcase_token_count)\n",
    "\n",
    "print(\"All files have generated succesfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cec7d9-c65a-490e-b562-c862609537eb",
   "metadata": {
    "id": "r-QvwLX1yLmF"
   },
   "source": [
    "# Answer 5 : precision, recall and F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604b476-3c3b-4641-83f2-b0c5f19950a8",
   "metadata": {},
   "source": [
    "## Function to calculate Precision , recall and F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "VmMds5Tn3oBi",
   "metadata": {
    "id": "VmMds5Tn3oBi"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted):\n",
    "    # Convert lists to sets\n",
    "    actual_set = set(actual)\n",
    "    predicted_set = set(predicted)\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = len(actual_set.intersection(predicted_set))\n",
    "    false_positives = len(predicted_set.difference(actual_set))\n",
    "    false_negatives = len(actual_set.difference(predicted_set))\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0fd883-5fec-43c7-b0dd-bddacc927247",
   "metadata": {},
   "source": [
    "### Function to clean token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5f4f3930-4b33-455a-bf7b-e2e238dfb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_token(words):\n",
    "        # Given list of strings\n",
    "        cleaned_words = []\n",
    "        # Remove special symbols from each word using regex\n",
    "        for word in words:\n",
    "            cleaned_word = \"\"\n",
    "            for x in word:\n",
    "                if (x in hindi_consonants_with_halant) or (x in map_to_vowel):\n",
    "                    cleaned_word += x\n",
    "            \n",
    "            cleaned_words.append(cleaned_word) \n",
    "        return  cleaned_words\n",
    "                    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bn7BMHwwuypE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bn7BMHwwuypE",
    "outputId": "e8d23b53-6b1a-4dc0-c6ce-4cf7a0d707f1"
   },
   "outputs": [],
   "source": [
    "my_sen = read_file(\"./data/25_sentence.txt\")\n",
    "Truth_vlaues = read_file(\"./data/TrueToken.txt\")\n",
    "# Truth_vlaues.to_list()\n",
    "Truth_value_list = Truth_vlaues['Text'].tolist()\n",
    "Truth_value_list = [token.strip() for sentence in Truth_value_list for token in sentence.split(',')]\n",
    "# print(Truth_value_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7558c-c1e6-4c53-8440-39d87657f1cd",
   "metadata": {},
   "source": [
    "## unigram tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0Np7iDUSwCvc",
   "metadata": {
    "id": "0Np7iDUSwCvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram_vocab_1000_token: ['▁हालांकि', ',', '▁म', 'ई', '▁2018', '▁में', '▁ए', 'न', 'आ', 'र']\n",
      "unigram_vocab_2000_token: ['▁हालांकि', ',', '▁म', 'ई', '▁2018', '▁में', '▁एन', 'आर', 'सी', '▁के']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unigram_vocab_1000_token, _  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/unigram_model/unigram_model_1000_vocab\",my_sen)\n",
    "unigram_vocab_2000_token, _  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/unigram_model/unigram_model_2000_vocab\",my_sen)\n",
    "\n",
    "print(f\"unigram_vocab_1000_token: {unigram_vocab_1000_token[:10]}\")\n",
    "print(f\"unigram_vocab_2000_token: {unigram_vocab_2000_token[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "n8hVi0Uqzo9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8hVi0Uqzo9a",
    "outputId": "a5c7c358-37e9-4841-d91b-d41b2697720a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Unigran with vocab size 1000:\n",
      "precision = 0.0\n",
      "recall = 0.0\n",
      "F-score = 0\n",
      "\n",
      "\n",
      "using Unigram with vocab size 2000:\n",
      "precision = 0.0\n",
      "recall = 0.0\n",
      "F-score = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1,r1,f1 = calculate_metrics(Truth_value_list,unigram_vocab_1000_token)\n",
    "print(\"using Unigran with vocab size 1000:\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,unigram_vocab_2000_token)\n",
    "print(\"using Unigram with vocab size 2000:\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6df5a3c-2e80-4e56-a50c-8481512e3068",
   "metadata": {},
   "source": [
    "#### we are getting all values  0 because unigram tokenizer tokenize values are as :\n",
    "#### unigram_vocab_1000_token: ['▁हालांकि', ',', '▁म', 'ई', '▁2018', '▁में', '▁ए', 'न', 'आ', 'र']\n",
    "#### unigram_vocab_2000_token: ['▁हालांकि', ',', '▁म', 'ई', '▁2018', '▁में', '▁एन', 'आर', 'सी', '▁के']\n",
    "\n",
    "\n",
    "#### which is noisy so hardly any token will match with the true value of token that's why we are getting Precision , recall and F-score all as 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d6aae-b200-4c84-a985-9befdec0254c",
   "metadata": {},
   "source": [
    "### now let's clean all token genereted by Unigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "da2d66fc-c158-49f1-8e97-daa56c204295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Unigran with vocab size 1000: For cleaned token\n",
      "precision = 0.13099041533546327\n",
      "recall = 0.13804713804713806\n",
      "F-score = 0.13442622950819674\n",
      "\n",
      "\n",
      "using Unigram with vocab size 2000:For cleaned token\n",
      "precision = 0.14130434782608695\n",
      "recall = 0.1750841750841751\n",
      "F-score = 0.15639097744360902\n"
     ]
    }
   ],
   "source": [
    "unigram_vocab_1000_token_cleaned = clean_token(unigram_vocab_1000_token)\n",
    "unigram_vocab_2000_token_cleaned = clean_token(unigram_vocab_2000_token)\n",
    "\n",
    "p1,r1,f1 = calculate_metrics(Truth_value_list,unigram_vocab_1000_token_cleaned)\n",
    "print(\"using Unigran with vocab size 1000: For cleaned token\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,unigram_vocab_2000_token_cleaned)\n",
    "print(\"using Unigram with vocab size 2000:For cleaned token\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be669379-6ba5-4155-8a26-af9408df4763",
   "metadata": {},
   "source": [
    "## BPE tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "tyRzw5jr86E_",
   "metadata": {
    "id": "tyRzw5jr86E_"
   },
   "outputs": [],
   "source": [
    "BPE_vocab_1000_token, _  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/BPE_model/BPE_model_1000_vocab\",my_sen)\n",
    "BPE_vocab_2000_token, _  = Unigram_and_BPE_tokenization(\"./Q4-Answer files/Trained model/BPE_model/BPE_model_2000_vocab\",my_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "NAcCq0Jw8zPQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAcCq0Jw8zPQ",
    "outputId": "7c119188-02b4-4b6d-c39f-35f3b073aa67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using BPE with vocab size 1000:\n",
      "precision = 0.002336448598130841\n",
      "recall = 0.003367003367003367\n",
      "F-score = 0.0027586206896551726\n",
      "\n",
      "\n",
      "using BPE with vocab size 2000:\n",
      "precision = 0.0\n",
      "recall = 0.0\n",
      "F-score = 0\n"
     ]
    }
   ],
   "source": [
    "p1,r1,f1 = calculate_metrics(Truth_value_list,BPE_vocab_1000_token)\n",
    "print(\"using BPE with vocab size 1000:\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,BPE_vocab_2000_token)\n",
    "print(\"using BPE with vocab size 2000:\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "029493d2-b1f9-48c3-ab9c-ae4bc3eaa270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using BPE with vocab size 1000: For cleaned token\n",
      "precision = 0.12596401028277635\n",
      "recall = 0.16498316498316498\n",
      "F-score = 0.14285714285714288\n",
      "\n",
      "\n",
      "using BPE with vocab size 2000:For cleaned token\n",
      "precision = 0.12596401028277635\n",
      "recall = 0.16498316498316498\n",
      "F-score = 0.14285714285714288\n"
     ]
    }
   ],
   "source": [
    "BPE_vocab_1000_token_cleaned = clean_token(BPE_vocab_1000_token)\n",
    "BPE_vocab_1000_token_cleaned = clean_token(BPE_vocab_2000_token)\n",
    "\n",
    "p1,r1,f1 = calculate_metrics(Truth_value_list,BPE_vocab_1000_token_cleaned)\n",
    "print(\"using BPE with vocab size 1000: For cleaned token\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,BPE_vocab_1000_token_cleaned)\n",
    "print(\"using BPE with vocab size 2000:For cleaned token\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd293f7-357d-486b-a25f-781a4e9fbf55",
   "metadata": {},
   "source": [
    "## mBERT tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "kV5X1fHe0Oev",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kV5X1fHe0Oev",
    "outputId": "0ed92810-b0f7-4133-cabe-d77bd4989450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mBERT with maxlength 1000:\n",
      "precision = 0.10501193317422435\n",
      "recall = 0.14814814814814814\n",
      "F-score = 0.12290502793296089\n",
      "\n",
      "\n",
      "using mBERT with maxlength 2000:\n",
      "precision = 0.10501193317422435\n",
      "recall = 0.14814814814814814\n",
      "F-score = 0.12290502793296089\n"
     ]
    }
   ],
   "source": [
    "mBERT_token_1000,_ = tokenization_step(mBERT_tokenizer,1000,'mBERT',my_sen)\n",
    "mBERT_token_2000,_ = tokenization_step(mBERT_tokenizer,2000,'mBERT',my_sen)\n",
    "p1,r1,f1 = calculate_metrics(Truth_value_list,mBERT_token_1000)\n",
    "print(\"using mBERT with maxlength 1000:\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,mBERT_token_2000)\n",
    "print(\"using mBERT with maxlength 2000:\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c3688-a8f8-43fc-bf8e-39cd1028f499",
   "metadata": {},
   "source": [
    "# IndicBERT tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "448a1467-19b5-489c-8ed8-07aa867b54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using IndicBERT with maxlength 1000:\n",
      "precision = 0.005277044854881266\n",
      "recall = 0.006734006734006734\n",
      "F-score = 0.005917159763313609\n",
      "\n",
      "\n",
      "using IndicBERT with maxlength 2000:\n",
      "precision = 0.005277044854881266\n",
      "recall = 0.006734006734006734\n",
      "F-score = 0.005917159763313609\n"
     ]
    }
   ],
   "source": [
    "IndicBERT_token_1000,_ =  tokenization_step(Indic_tokenizer,1000,'IndicBERT',my_sen)\n",
    "IndicBERT_token_2000,_ =  tokenization_step(Indic_tokenizer,2000,'IndicBERT',my_sen)\n",
    "p1,r1,f1 = calculate_metrics(Truth_value_list,IndicBERT_token_1000)\n",
    "print(\"using IndicBERT with maxlength 1000:\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")\n",
    "p2,r2,f2 = calculate_metrics(Truth_value_list,IndicBERT_token_2000)\n",
    "print(\"using IndicBERT with maxlength 2000:\")\n",
    "print(f\"precision = {p2}\\nrecall = {r2}\\nF-score = {f2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add651d0-0606-4a1d-9b93-78ca6f1307a0",
   "metadata": {},
   "source": [
    "## Withespace tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "lDjeAHoD6CN8",
   "metadata": {
    "id": "lDjeAHoD6CN8"
   },
   "outputs": [],
   "source": [
    "whitespace_tokenizer_token,_ = whitespace_tokenizer(my_sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7eb36232-b65d-48ae-8196-49d1ae7dd67f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOLidBEU9OiG",
    "outputId": "a5ae7b1e-39fe-474e-ffae-8a382627171a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Whitespace tokenization:\n",
      "precision = 0.35174418604651164\n",
      "recall = 0.4074074074074074\n",
      "F-score = 0.3775351014040562\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1,r1,f1 = calculate_metrics(Truth_value_list,whitespace_tokenizer_token)\n",
    "print(\"using Whitespace tokenization:\")\n",
    "print(f\"precision = {p1}\\nrecall = {r1}\\nF-score = {f1}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7bdcc-f413-40ff-b7ba-0ca377d08208",
   "metadata": {
    "id": "4wnrjeQ79aXb"
   },
   "source": [
    "# Answer 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701007da-3589-436b-9b3c-1cb9c6d35829",
   "metadata": {},
   "source": [
    "Unigram with Vocab Size 1000 and 2000: Both versions of the unigram tokenization show relatively low precision, recall, and F-score. The precision and recall increase slightly when using a larger vocabulary size.\n",
    "Unigram tokenization doest not perfoem good because generated tokens are very noisy so calculated values are 0.0\n",
    "but when we cleaned tokens then results become better.\n",
    "\n",
    "BPE (Byte Pair Encoding) with Vocab Size 1000 and 2000: BPE tokenization performs poorly in terms of precision, recall, and F-score compared to other methods, with very low values observed for all metrics.\n",
    "\n",
    "similarly for BPE  tokenization doest not perfoem good because generated tokens are very noisy so calculated values are near to 0.0. but after cleaning results became quite well.\n",
    "\n",
    "Whitespace Tokenization: Using whitespace tokenization shows higher precision, recall, and F-score compared to other tokenization methods. It achieves the highest precision and recall among all methods.\n",
    "\n",
    "mBERT with Max Length 1000 and 2000: Both versions of mBERT exhibit similar precision, recall, and F-score. These scores are moderate, falling between those of unigram and whitespace tokenization.\n",
    "\n",
    "Whitespace tokenization appears to be the most effective method among those tested, with the highest precision, recall, and F-score.\r\n",
    "Unigram tokenization performs better than BPE, but still shows lower performance compared to whitespace tokenization\n",
    ".\r\n",
    "mBERT shows moderate performance, but it doesn't seem to improve significantly when increasing the max length from 1000 to 2000\n",
    "when using IndicBERT with both a maximum length of 1000 and 2000, the precision, recall, and F-score remain the same. This suggests that increasing the maximum length from 1000 to 2000 doesn't lead to any improvement in performance for the given task..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f822a0-2d3c-4fb1-9d69-f24e6edef0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00691d80a0534d96a2b3a758f06c468a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "063c8094343b4dfa906e2b4bb6812915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e764f07298a4ca3ae0464c6826370d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69501c90e60e4066a4a599f69a237311",
      "placeholder": "​",
      "style": "IPY_MODEL_063c8094343b4dfa906e2b4bb6812915",
      "value": "config.json: 100%"
     }
    },
    "237dd2b7df8247e991bb448e61c98e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28667b8b571342acab0aeeae3d5bbdb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301c7cb8821d46f1ba857e4d7bb39be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3939ae9f38640c9817300dd542ed94d",
       "IPY_MODEL_a149c5f814194f328379a9506e3284a0",
       "IPY_MODEL_e1a5a843c9114c8bbd59c84d9e8c698c"
      ],
      "layout": "IPY_MODEL_28667b8b571342acab0aeeae3d5bbdb5"
     }
    },
    "65e24d0503994f8893c8adde322969a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69501c90e60e4066a4a599f69a237311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9248c179265b45cdbbf08fd92eaa4a9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b828cb7454345589a99bb43c5ea2f8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8fe8e3396f34edabf7597cca66088dd",
      "max": 507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_237dd2b7df8247e991bb448e61c98e16",
      "value": 507
     }
    },
    "a07a0d0bc0d34ebe9d1a1730010d0185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a149c5f814194f328379a9506e3284a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9248c179265b45cdbbf08fd92eaa4a9b",
      "max": 5646064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a07a0d0bc0d34ebe9d1a1730010d0185",
      "value": 5646064
     }
    },
    "a8160c1596ce4d73bf2d46868f71aeae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e764f07298a4ca3ae0464c6826370d2",
       "IPY_MODEL_9b828cb7454345589a99bb43c5ea2f8c",
       "IPY_MODEL_f4a41a33dc5c4813b958bba004ca2566"
      ],
      "layout": "IPY_MODEL_fa5d96e35a2b4f03ac73ad4de273d3a3"
     }
    },
    "c8fe8e3396f34edabf7597cca66088dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db420eea2d474427abce15b033fd5f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e09d6e0780704603906521cd9ccb8a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1a5a843c9114c8bbd59c84d9e8c698c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65e24d0503994f8893c8adde322969a0",
      "placeholder": "​",
      "style": "IPY_MODEL_db420eea2d474427abce15b033fd5f85",
      "value": " 5.65M/5.65M [00:00&lt;00:00, 18.1MB/s]"
     }
    },
    "ea01a2a7836c43bd9119ad8bb052668a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3939ae9f38640c9817300dd542ed94d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca72bd9d12244f383138f2f90113b63",
      "placeholder": "​",
      "style": "IPY_MODEL_e09d6e0780704603906521cd9ccb8a2e",
      "value": "spiece.model: 100%"
     }
    },
    "f4a41a33dc5c4813b958bba004ca2566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00691d80a0534d96a2b3a758f06c468a",
      "placeholder": "​",
      "style": "IPY_MODEL_ea01a2a7836c43bd9119ad8bb052668a",
      "value": " 507/507 [00:00&lt;00:00, 26.9kB/s]"
     }
    },
    "fa5d96e35a2b4f03ac73ad4de273d3a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fca72bd9d12244f383138f2f90113b63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
